{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb94174",
   "metadata": {},
   "source": [
    "<img width=\"200\" style=\"float:left\" \n",
    "     src=\"https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf9ef9",
   "metadata": {},
   "source": [
    "<img width=\"500\" style=\"float:center\" \n",
    "     src=\"https://images6.alphacoders.com/119/1191374.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7dc66",
   "metadata": {},
   "source": [
    "# Twitter Structured Streaming 🦑\n",
    "* [Business Case](#0)\n",
    "* [1. Setup](#1) \n",
    "  * [1.1 Start the Kafka service and the producer](#1.1)\n",
    "  * [1.2 Search for Spark Installation](#1.2)\n",
    "  * [1.3 Create SparkSession](#1.3)\n",
    "* [2. Twitter & SquidGame](#2) \n",
    "  * [2.1 Create a Streaming DataFrame](#2.1)\n",
    "  * [2.2 Transform the DataFrame](#2.2)\n",
    "  * [2.3 Applying the Streaming Logic per Question](#2.3)\n",
    "* [3. Questions](#3)\n",
    "  * [3.1 Conversation: What are the top 10 hashtags in the SquidGame conversation?](#3.1)\n",
    "  * [3.2 Conversation: Top 10 most common languages on the conversation of SquidGame.](#3.2)\n",
    "  * [3.3 Conversation: Who are the top 5 chit-chatter in the SquidGame conversation?](#3.3)\n",
    "  * [3.4 Conversation Background: What are the top 10 locations in the SquidGame conversation?](#3.4)\n",
    "  * [3.5 Giving context to Location - Checking how many users have their geotag enabled.](#3.5)\n",
    "  * [3.6 Conversation Background: How are they tweeting? Top 5 technical sources used by Twitter Users.](#3.6)\n",
    "  * [3.7 Influencers: Who are the top 10 accounts mentioned in the SquidGame Conversation?](#3.7)\n",
    "  * [3.8 Influencers: Who are the most replied users in the SquidGame conversation?](#3.8)\n",
    "  * [3.9 Who are the users? The ratio of Verified accounts in the conversation of SquidGame.](#3.9)\n",
    "  * [3.10 Influencer: Who are the verified accounts tweeting about SquidGame?](#3.10)\n",
    "  * [3.11 Influencers: Top 5 most followed users in our SquidGame Conversation.](#3.11)\n",
    "  * [3.12 Given the development of the SquidGame coin in the last season's launch, are there cashtags embedded in the SquidGame conversation? What are the top 5?](#3.12)\n",
    "* [4. Please, terminate the tools used.](#4)\n",
    "  * [4.1 Stop the Spark Streaming application](#4.1)\n",
    "  * [4.2 Stop the Kafka producer](#4.2)\n",
    "  * [4.3 Stop the Kafka service](#4.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b7c91",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Business Case 📎\n",
    "To further understand user's behavior and find valuable insights for the future marketing campaign of the second season of Squid Game, Netflix has asked Team H, as analytics consultants, to set up a structured streaming Pipeline using Kafka of the conversation of Squid Game on Twitter to provide live insights for both marketing and sales team. Hence, to find valuable information, Team H has established 12 key business questions aligned with the Marketing and Sales strategy following three different pillars: Quick insights on the conversation, Conversation Background, and Insights on the Influencers. Hence, this Jupyter Notebook is a compilation of ready-to-query consumer-insights questions that aims to support those strategic teams with live insights of the Squid Game conversations.\n",
    "\n",
    "</div>\n",
    "\n",
    "<ul class=\"roman\">\n",
    "     <li> Quick insights on the Conversation</li>\n",
    "     <ul class=\"square\">\n",
    " <li>1. Conversation: What are the top 10 hashtags in the SquidGame conversation?</li>\n",
    " <li>2. Conversation: Top 10 most common languages on the conversation of SquidGame.</li>\n",
    " <li>3. Conversation: Who are the top 5 chit-chatter in the SquidGame conversation?\n",
    " </ul>\n",
    " <li>Conversation Background:\n",
    " <ul class=\"square\">\n",
    " <li>4. Conversation Background: What are the top 10 locations in the SquidGame conversation?</li>\n",
    " <li>5. Conversation Background: Giving context to Location - Checking how many users have their geotag enabled.</li>\n",
    " <li>6. Conversation Background: How are they tweeting? Top 5 technical sources used by Twitter Users.</li>\n",
    "  </ul>\n",
    " <li>Influencers:\n",
    " <ul class=\"square\">\n",
    " <li>7. Influencers: Who are the top 10 accounts mentioned in the SquidGame Conversation?\n",
    " <li>8. Influencers: Who are the most replied users in the SquidGame conversation?\n",
    " <li>9. Influences: Who are the users? The ratio of Verified accounts in the conversation of SquidGame.\n",
    " <li>10. Influencer: Who are the verified accounts tweeting about SquidGame?\n",
    " <li> 11. Influencers: Top 5 most followed users in our SquidGame Conversation.\n",
    " <li> 12. Coins: Given the development of the SquidGame coin in the last season's launch, are there cashtags embedded in the SquidGame conversation? What are the top 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81aa63",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Seting Up 🧹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331e2ce",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "### 1.1 Starting with Kafka service and the producer \n",
    "<p>Dear Marketing Team, before starting to use this notebook please be sure that you log into the course environment by:</p>\n",
    "<ul>\n",
    "    <li><p><b>Start the Kafka service</b>:\n",
    "        <br/><em>\\$ sudo service kafka start</p></em><br/></li>\n",
    "    <li>Add your <b>API key</b>, <b>API secret</b>, <b>access token</b> and <b>access secret</b> to the credentials.ini file</li>\n",
    "    <li><p><b>Start the producer</b> connecting to Twitter and filtering tweets by keywords or hashtags:\n",
    "        <br/>\\$ python3 twitter_producer.py credentials.ini \"squidgame,#SquidGame, #sg2, #squidgame2, #season2sg\" -b localhost:9092 -t tweets</p></li>\n",
    "</ul>\n",
    "Please, also don't forget to pip install tweepy with \n",
    "**-m pip install --upgrade pip**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff256c43",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "### 1.2 Searching for the Spark Installation \n",
    "This step is required just because we are working in the course environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69246e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82ec90",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "### 1.3 Creating SparkSession\n",
    "\n",
    "In addition to create the Spark Session, we need to set up a variable environment to include extra libraries in our \"cluster\".<br/>\n",
    "In this case we're including the Spark package as our job will connect to Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26503986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark3/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/osbdet/.ivy2/cache\n",
      "The jars for the packages stored in: /home/osbdet/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/opt/spark3/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2f754186-817b-4b95-b56d-aac91246502e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 420ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.3 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2f754186-817b-4b95-b56d-aac91246502e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/12ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.3\" pyspark-shell'\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d68f9",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2. Twitter & SquidGame 🤓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee50d87",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "### 2.1 Creating a Streaming DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16cca2",
   "metadata": {},
   "source": [
    "Here, we are creating a **streaming** DataFrame called tweets_raw from the Kafka stream. \n",
    "\n",
    "- format: **kafka** \n",
    "- kafka.bootstrap.servers: **localhost:9092** \n",
    "- subscribe: **tweets**\n",
    "- startingOffsets: **latest**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be323cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_raw = (spark.readStream\n",
    "                   .format(\"kafka\")\n",
    "                   .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "                   .option(\"subscribe\", \"tweets\")\n",
    "                   .option(\"startingOffsets\", \"latest\")\n",
    "                   .load())\n",
    "\n",
    "tweets_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb2dd8",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "### 2.2 Transform the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969efb1",
   "metadata": {},
   "source": [
    "This step is important, since we are translating the tweet in its proper structure.\n",
    "\n",
    "The contents of the value column are tweets in JSON format. The JSON structure is defined in the official Twitter developer website and is the following:\n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet\n",
    "\n",
    "Importantly, it is **not mandatory to define all the JSON properties** in the schema definition, however since this notebook is supposed to be ready-to-query we thought it would be important to translate everything to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7001996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_schema=\"\"\"\n",
    "created_at string,\n",
    "id bigint,\n",
    "id_str string,\n",
    "text string,\n",
    "source string,\n",
    "truncated boolean,\n",
    "in_reply_to_status_id bigint,\n",
    "in_reply_to_status_id_str string,\n",
    "in_reply_to_user_id bigint,\n",
    "in_reply_to_user_id_str string,\n",
    "in_reply_to_screen_name string,\n",
    "`user` struct<\n",
    "            id:bigint,\n",
    "            id_str:string,\n",
    "            name:string,\n",
    "            screen_name:string,\n",
    "            location:string,\n",
    "            url:string,\n",
    "            description:string,\n",
    "            protected:boolean,\n",
    "            verified:boolean,\n",
    "            followers_count:bigint,\n",
    "            friends_count:bigint,\n",
    "            listed_count:bigint,\n",
    "            favourites_count:bigint,\n",
    "            statuses_count:bigint,\n",
    "            created_at:string,\n",
    "            profile_banner_url:string,\n",
    "            profile_image_url_https:string,\n",
    "            default_profile:boolean,\n",
    "            default_profile_image:boolean,\n",
    "            withheld_in_countries: array<string>,\n",
    "            withheld_scope:string,\n",
    "            geo_enabled:boolean\n",
    "            >,\n",
    "coordinates struct <\n",
    "            coordinates:array<float>,\n",
    "            type:string\n",
    "            >,\n",
    "place struct<\n",
    "            country:string,\n",
    "            country_code:string,\n",
    "            full_name:string,\n",
    "            place_type:string,\n",
    "            url:string\n",
    "            >,\n",
    "quoted_status_id bigint,\n",
    "quoted_status_id_str string,\n",
    "is_quote_status boolean,\n",
    "quote_count bigint,\n",
    "reply_count bigint,\n",
    "retweet_count bigint,\n",
    "favorite_count bigint,\n",
    "entities struct<\n",
    "            user_mentions:array<struct<screen_name:string>>,\n",
    "            hashtags:array<struct<text:string>>, \n",
    "            media:array<struct<expanded_url:string>>, \n",
    "            urls:array<struct<expanded_url:string>>, \n",
    "            symbols:array<struct<text:string>>\n",
    "            >,\n",
    "favorited boolean,\n",
    "retweeted boolean,\n",
    "possibly_sensitive boolean,\n",
    "filter_level string,\n",
    "lang string\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0c8bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet: struct (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |    |-- truncated: boolean (nullable = true)\n",
      " |    |-- in_reply_to_status_id: long (nullable = true)\n",
      " |    |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: long (nullable = true)\n",
      " |    |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |    |-- user: struct (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- location: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |-- verified: boolean (nullable = true)\n",
      " |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |-- listed_count: long (nullable = true)\n",
      " |    |    |-- favourites_count: long (nullable = true)\n",
      " |    |    |-- statuses_count: long (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |-- withheld_in_countries: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- withheld_scope: string (nullable = true)\n",
      " |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- coordinates: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- place: struct (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- country_code: string (nullable = true)\n",
      " |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |-- place_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |-- quoted_status_id: long (nullable = true)\n",
      " |    |-- quoted_status_id_str: string (nullable = true)\n",
      " |    |-- is_quote_status: boolean (nullable = true)\n",
      " |    |-- quote_count: long (nullable = true)\n",
      " |    |-- reply_count: long (nullable = true)\n",
      " |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- favorite_count: long (nullable = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |-- symbols: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- favorited: boolean (nullable = true)\n",
      " |    |-- retweeted: boolean (nullable = true)\n",
      " |    |-- possibly_sensitive: boolean (nullable = true)\n",
      " |    |-- filter_level: string (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "tweets = (tweets_raw.selectExpr(\"cast(value as string)\") \n",
    "                    .select(from_json(col(\"value\"), tweet_schema).alias(\"tweet\")))\n",
    "                      \n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf90f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tweet: struct<created_at:string,id:bigint,id_str:string,text:string,source:string,truncated:boolean,in_reply_to_status_id:bigint,in_reply_to_status_id_str:string,in_reply_to_user_id:bigint,in_reply_to_user_id_str:string,in_reply_to_screen_name:string,user:struct<id:bigint,id_str:string,name:string,screen_name:string,location:string,url:string,description:string,protected:boolean,verified:boolean,followers_count:bigint,friends_count:bigint,listed_count:bigint,favourites_count:bigint,statuses_count:bigint,created_at:string,profile_banner_url:string,profile_image_url_https:string,default_profile:boolean,default_profile_image:boolean,withheld_in_countries:array<string>,withheld_scope:string,geo_enabled:boolean>,coordinates:struct<coordinates:array<float>,type:string>,place:struct<country:string,country_code:string,full_name:string,place_type:string,url:string>,quoted_status_id:bigint,quoted_status_id_str:string,is_quote_status:boolean,quote_count:bigint,reply_count:bigint,retweet_count:bigint,favorite_count:bigint,entities:struct<user_mentions:array<struct<screen_name:string>>,hashtags:array<struct<text:string>>,media:array<struct<expanded_url:string>>,urls:array<struct<expanded_url:string>>,symbols:array<struct<text:string>>>,favorited:boolean,retweeted:boolean,possibly_sensitive:boolean,filter_level:string,lang:string>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8576feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- twitter_created_at: string (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- favourites_count: long (nullable = true)\n",
      " |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "tweets_df = tweets.select(col(\"tweet.user.name\").alias(\"name\"), col(\"tweet.user.location\").alias(\"location\"), col(\"tweet.user.description\").alias(\"description\"), col(\"tweet.user.created_at\").alias(\"twitter_created_at\"), col(\"tweet.user.followers_count\").alias(\"followers_count\"), col(\"tweet.user.friends_count\").alias(\"friends_count\"), col(\"tweet.user.favourites_count\").alias(\"favourites_count\"), col(\"tweet.user.verified\").alias(\"verified\"))\n",
    "tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b39dd",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "### 2.3 Applying the Streaming Logic per Question\n",
    "\n",
    "In this notebook, we will be answering 12 essential business questions for both the marketing and sales team to better understand the conversation of SquidGame on Twitter. The process of each question uses the exact step-by-step process defined below. \n",
    "\n",
    "<li> Step 1: Applying transformations to the dataframe. </li>\n",
    "<li> Step 2: Normalizing the subject at hand to lower case so they can be grouped more easily and account for different. \n",
    "<li> Step 3: Sinking the streaming DataFrame. </li>\n",
    "<li> Step 4: Action the stream by calling the start method. </li>\n",
    "<li> Step 5: Checking results since we defined sink to keep the data in memory as a table. </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853f902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079b84b",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "**1. Conversation: What are the top 10 hashtags in the SquidGame conversation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5836d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hashtag: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = (tweets.select(explode(\"tweet.entities.hashtags.text\").alias(\"hashtag\")))                \n",
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec6fd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hashtag: string, count: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_hashtags = (hashtags.withColumn(\"hashtag\",lower(\"hashtag\"))\n",
    "                    .groupBy(\"hashtag\").count())\n",
    "trending_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce3f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7fab1c04b828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_hashtags = (trending_hashtags.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_hashtags_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2eb774",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_hashtags.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  hashtag|count|\n",
      "+---------+-----+\n",
      "|squidgame|    1|\n",
      "|  binarmy|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_hashtags_query order by count desc limit 10\").show()\n",
    "    \n",
    "#Please, interrupet the kernel before jumping to the next question. You should get get KeyboardInterrupt message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29afb6",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "**2. Conversation: Top 10 most common languages on the conversation of SquidGame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38f6f140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = (tweets.select(lower(\"tweet.lang\").alias(\"language\")))                \n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fba5a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string, count: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_languages = (languages.groupBy(\"language\").count())\n",
    "trending_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447c57f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7fab11d23e48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_languages = (trending_languages.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_languages_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b78f1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_languages.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092f0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|language|count|\n",
      "+--------+-----+\n",
      "|      en|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_languages_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30374a3a",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "**3. Conversation: Who are the top 5 chit-chatter in the SquidGame conversation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c76f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = (tweets.select(\"tweet.user.screen_name\"))               \n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642f66ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string, count: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_users = (users.withColumn(\"screen_name\",lower(\"screen_name\"))\n",
    "                    .groupBy(\"screen_name\").count())\n",
    "trending_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b945c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f92163875f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_users = (trending_users.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_users_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aaae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_users.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e0cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|    screen_name|count|\n",
      "+---------------+-----+\n",
      "|        raart96|    2|\n",
      "| cemalturkmen15|    1|\n",
      "|forbeslifelatam|    1|\n",
      "|         fiztwt|    1|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:==========================================>           (159 + 4) / 200]\r"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_users_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed2731b",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "**4. Conversation Background: What are the top 10 locations in the SquidGame conversation?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "364666a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country_code: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = (tweets.select(\"tweet.place.country_code\").alias(\"user_location\"))                \n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c834ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country_code: string, count: bigint]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_locations = (locations.withColumn(\"user_location.country_code\",lower(\"user_location.country_code\"))\n",
    "                    .groupBy(\"user_location.country_code\").count())\n",
    "trending_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769cbc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f9216367240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_locations = (trending_locations.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_locations_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7501bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_locations.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|country_code|count|\n",
      "+------------+-----+\n",
      "|        null|    2|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_locations_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbde79",
   "metadata": {},
   "source": [
    "<a id='3.5'></a>\n",
    "**5. Conversation Background: Giving context to Location - Checking how many users have their geotag enabled.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54da2394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[geo_enabled: boolean]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geotag_booleans = (tweets.select(\"tweet.user.geo_enabled\").alias(\"geo_enabled\"))                \n",
    "geotag_booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "659e2e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[geo_enabled: string, count: bigint]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_geotag_booleans = (geotag_booleans.withColumn(\"geo_enabled\",lower(\"geo_enabled\"))\n",
    "                    .groupBy(\"geo_enabled\").count())\n",
    "trending_geotag_booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e97022a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f921635a048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_geotag_booleans = (trending_geotag_booleans.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_geotag_booleans_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_geotag_booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f437f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_geotag_booleans.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f86c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|geo_enabled|count|\n",
      "+-----------+-----+\n",
      "|      false|    8|\n",
      "|       true|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_geotag_booleans_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a8872",
   "metadata": {},
   "source": [
    "<a id='3.6'></a>\n",
    "**6. Conversation Background: How are they tweeting? Top 5 technical sources used by Twitter Users.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e24f092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[source: string]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 307:(128 + 4) / 200][Stage 308:>  (0 + 0) / 1][Stage 310:>  (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "sources = (tweets.select(\"tweet.source\").alias(\"source\"))               \n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a5d7b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 307:(142 + 4) / 200][Stage 308:>  (0 + 0) / 1][Stage 310:>  (0 + 0) / 1]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[source: string, count: bigint]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trending_sources = (sources.withColumn(\"source\",lower(\"source\"))\n",
    "                    .groupBy(\"source\").count())\n",
    "trending_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c89a820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f921635a6d8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_sources = (trending_sources.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_sources_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "795fff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 309:(78 + 4) / 200][Stage 311:>(0 + 0) / 200][Stage 313:>(0 + 0) / 200]0]\r"
     ]
    }
   ],
   "source": [
    "query = stream_writer_sources.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8955346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              source|count|\n",
      "+--------------------+-----+\n",
      "|<a href=\"http://t...|    4|\n",
      "|<a href=\"http://t...|    2|\n",
      "|<a href=\"https://...|    1|\n",
      "|<a href=\"https://...|    1|\n",
      "|<a href=\"https://...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_sources_query order by count desc limit 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0b551",
   "metadata": {},
   "source": [
    "<a id='3.7'></a>\n",
    "**7. Influencers: Who are the top 10 accounts mentioned in the SquidGame Conversation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8891aa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[mention: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying transformations to the dataframe\n",
    "mentions = (tweets.select(explode(\"tweet.entities.user_mentions.screen_name\").alias(\"mention\")))                 \n",
    "mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b87fec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[mention: string, count: bigint]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing the mentions to lower case and grouping\n",
    "trending_mentions = (mentions.withColumn(\"mention\",lower(\"mention\"))\n",
    "                    .groupBy(\"mention\").count())\n",
    "trending_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b636a107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f92162e0fd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sinking the streaming DataFrame\n",
    "#format: memory\n",
    "#outputMode: complete\n",
    "#trigger: 2 seconds\n",
    "stream_writer_mentions = (trending_mentions.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_mentions_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cb370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actioning the stream by calling the start method\n",
    "query = stream_writer_mentions.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|mention|count|\n",
      "+-------+-----+\n",
      "| yoo_i_|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking results since we defined sink to keep the data in memory as a table\n",
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_mentions_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90994315",
   "metadata": {},
   "source": [
    "<a id='3.8'></a>\n",
    "**8. Influencers: Who are the most replied users in the SquidGame conversation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0253cd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[in_reply_to_screen_name: string]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies = (tweets.select(\"tweet.in_reply_to_screen_name\").alias(\"reply\"))                \n",
    "replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1b9f78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 569:================================================>    (183 + 4) / 200]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[in_reply_to_screen_name: string, count: bigint]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_replies = (replies.withColumn(\"reply.in_reply_to_screen_name\",lower(\"reply.in_reply_to_screen_name\"))\n",
    "                    .groupBy(\"reply.in_reply_to_screen_name\").count())\n",
    "trending_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e3b6892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 569:===================================================> (196 + 4) / 200]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f9216301780>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stream_writer_replies = (trending_replies.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_replies_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "998d5629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = stream_writer_replies.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f193b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|in_reply_to_screen_name|count|\n",
      "+-----------------------+-----+\n",
      "|                   null|    3|\n",
      "|        Gdr2VS8mZG1UEYg|    1|\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_replies_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578cd88",
   "metadata": {},
   "source": [
    "<a id='3.9'></a>\n",
    "**9. Influences: Who are the users? The ratio of Verified accounts in the conversation of SquidGame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "887b4ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[verified: boolean]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verified_status = (tweets.select(\"tweet.user.verified\"))                 \n",
    "verified_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a50f2a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[verified: string, count: bigint]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_status = (verified_status.withColumn(\"verified\",lower(\"verified\"))\n",
    "                    .groupBy(\"verified\").count())\n",
    "trending_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "735a913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f9216319630>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_status = (trending_status.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_status_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b405b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_status.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7508527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|verified|count|\n",
      "+--------+-----+\n",
      "|   false|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_status_query order by count desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de36667",
   "metadata": {},
   "source": [
    "<a id='3.10'></a>\n",
    "**10. Influencer: Who are the verified accounts tweeting about SquidGame?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a709ef1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string, verified: boolean]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verified_users = (tweets.select(\"tweet.user.screen_name\", col(\"tweet.user.verified\").alias(\"verified\")))                 \n",
    "verified_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c17cf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string, count: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_verified_users = verified_users.where(col(\"verified\") == \"True\").select(\"screen_name\").groupBy(\"screen_name\").count()\n",
    "trending_verified_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1eb360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f95f0c52940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_verified_users = (trending_verified_users.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_verified_users_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_verified_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f75be300",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_verified_users.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|screen_name|count|\n",
      "+-----------+-----+\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_verified_users_query\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3665e8",
   "metadata": {},
   "source": [
    "<a id='3.11'></a>\n",
    "**11. Influencers: Top 5 most followed users in our SquidGame Conversation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122c59f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string, followers: bigint]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_followed = (tweets.select(\"tweet.user.screen_name\", col(\"tweet.user.followers_count\").alias(\"followers\")))                 \n",
    "most_followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7af54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string, count: bigint]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_most_followed = most_followed.groupBy(\"screen_name\").count()\n",
    "trending_most_followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39a9bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f5448864630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_most_followed = (trending_most_followed.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_verified_users_query\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_most_followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0630aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_most_followed.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39385e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|screen_name|\n",
      "+-----------+\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select screen_name from trending_verified_users_query order by count desc limit 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c987d07",
   "metadata": {},
   "source": [
    "<a id='3.12'></a>\n",
    "**12. Coins: Given the development of the SquidGame coin in the last season's launch, are there cashtags embedded in the SquidGame conversation? What are the top 5?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98df6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cashtag: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cashtags = (tweets.select(explode(\"tweet.entities.symbols.text\").alias(\"cashtag\")))\n",
    "cashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6fda30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cashtag: string, count: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_cashtags = (cashtags.withColumn(\"cashtag\",upper(\"cashtag\"))\n",
    "                    .groupBy(\"cashtag\").count())\n",
    "trending_cashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa77ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.DataStreamWriter at 0x7f84d55f76a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_writer_cashtags = (trending_cashtags.writeStream\n",
    "                         .format(\"memory\")\n",
    "                         .queryName(\"trending_cashtags_now\")\n",
    "                         .outputMode(\"complete\")\n",
    "                         .trigger(processingTime='2 seconds'))\n",
    "stream_writer_cashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5e2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = stream_writer_cashtags.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|cashtag|count|\n",
      "+-------+-----+\n",
      "|  SQUID|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "while(True):\n",
    "    time.sleep(10)\n",
    "    clear_output(wait=False)\n",
    "    spark.sql(\"select * from trending_cashtags_now order by count desc limit 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5619c6e",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4. Please, terminate the tools used. 🙅🏼‍♀️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3e5bd",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "### 3.1 Stop the Spark Streaming application\n",
    "In order to stop the Spark Streaming application go to **Kernel -> Shutdown**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ddeae",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "### 4.2 Stop the Kafka producer\n",
    "Go to the terminal where you started the producer and **press Ctrl + C**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394c0fe",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "### 4.3 Stop the Kafka service\n",
    "<p>Go to a terminal windows and type the following command:</p>\n",
    "<em>$ sudo service kafka stop</em>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
